{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Implementing K-Nearest Neighbors\n",
    "\n",
    "K-Neareset Neighbors is a simple algorithm you can read about on Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm). \n",
    "\n",
    "Let's implement K-Nearest Neighbors in Python. Assume your data to be one-dimensional (only one feature). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Let's implement the KNN algorithm. \n",
    "\n",
    "def knn(K, X, y, new_x):\n",
    "    \"\"\" The KNN algorithm for one-dimensional data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    K : natural number\n",
    "    \tThe number of neighbors!\n",
    "    X : list of floats\n",
    "    \tThe features of the data\n",
    "    y : list of integers \\in {0,1}\n",
    "    \tThe labels of the data\n",
    "    new_x : float\n",
    "    \tThe data point to predict a label for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_y: float\n",
    "    \tThe predicted value for the data point\n",
    "    \"\"\"\n",
    "\n",
    "    # HINT: make a small helper function for each of the steps: \n",
    "    # 1. Get the distances from each data point in X to new_x (|a - b|)\n",
    "    # 2. Zip together the distances and labels, then sort by distance. \n",
    "    # 3. Grab the first K labels and average them.\n",
    "    # 4. Return the average!\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "with open('classification_data.csv', 'r') as f:\n",
    "    dat = list(reader(f))[1:]\n",
    "    dat = [[float(x), int(label)] for x,label in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# In your data, \"X\" is a data point that is nothing more than\n",
    "# a single number. \n",
    "# Shuffle your data into a random order \n",
    "# HINT: use https://docs.python.org/3/library/random.html#random.shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# If you shuffled your data, this test should pass\n",
    "# (i.e. not throw an error)\n",
    "\n",
    "assert(sum([label for x,label in dat[:50]]) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Split your data, which is now a list, into 2 sublists:\n",
    "# \"train\" and \"test\"\n",
    "# The \"train\" group should have 700 elements\n",
    "# The test group should have 300 element\n",
    "# Each group should have the same format as the original data\n",
    "\n",
    "train, test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Now you will need to make another split, within the groups!\n",
    "# For each group (\"train\" and \"test\") split the X's from the labels.\n",
    "\n",
    "X_train, y_train = \n",
    "X_test, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Test how well your function does on predicting the data.\n",
    "# Hint: X_train should be X, and y_train the y in your knn function. \n",
    "# Then you should call the knn function for each data point in your test set, \n",
    "# with new_x equal to each x in x_test. \n",
    "# The result should be a good prediction of \n",
    "\n",
    "def test_knn(K, X_train, y_train, X_test, y_test):\n",
    "    \"\"\" Tests the function knn on the given train/test data. \"\"\"\n",
    "    # for each data point in X_test, call the function knn and \n",
    "    # get a prediction. See if the prediction is equal to the label\n",
    "    # from y_test. Return the accuracy of your model. \n",
    "\n",
    "    pass\n",
    "\n",
    "assert(test_knn(30, X_train, y_train, X_test, y_test) == .75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
